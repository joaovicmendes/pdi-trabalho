{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação de dígitos utilizando descritores de redes neurais e classificador SVM\n",
    "\n",
    "Veremos um exemplo de uso de uma rede neural para obtenção de descritores de imagens. O exemplo foi feito de forma que não seja necessário treinar a rede em nenhum momento. Para uma aplicação real, é mais comum que o final da rede seja adaptado de forma que não seja necessário o uso do classificador SVM. Mas nesse caso é necessário realizar um treinamento adicional da rede.\n",
    "\n",
    "Vamos considerar que as imagens a serem utilizadas estão organizadas em diretórios da seguinte forma:\n",
    "\n",
    "```\n",
    "digitos  \n",
    "│\n",
    "└───treinamento\n",
    "│   │   digito_0_imagem_0.png\n",
    "│   │   digito_0_imagem_1.png\n",
    "│   │   ...\n",
    "│   │   digito_1_imagem_0.png\n",
    "│   │   digito_1_imagem_2.png\n",
    "│   │   ...\n",
    "│   │   digito_9_imagem_0.png\n",
    "│   │   digito_9_imagem_1.png\n",
    "│   │   ...\n",
    "│  \n",
    "└───teste\n",
    "    │   imagem_0.png\n",
    "    │   imagem_1.png\n",
    "    │   imagem_2.png\n",
    "    │   ...\n",
    "```\n",
    "\n",
    "O diretório `treinamento` possui 1000 imagens para cada dígito. O diretório `teste` possui algumas imagens cuja classe é desconhecida. Essas imagens serão classificadas após o trainamento do classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso você não tenha uma placa de vídeo possuindo núcleos CUDA (placas da NVIDIA), você pode tentar executar esse notebook no Google Colab:\n",
    "\n",
    "https://colab.research.google.com/drive/1ytJzUos-DKVtnuxuugKFccWOS5UIfgfN?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação de bibliotecas e definição de funções básicas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                  # (testado na versão 1.17.4)\n",
    "import sklearn.svm                  # scikit-learn (testado na versão 0.22.1)\n",
    "from PIL import Image               # Para leitura de imagens (testado na versão 6.2.1)\n",
    "import os                           # Biblioteca padrão do Python com funções de sistema operacional (versão Python 3.7.4)\n",
    "import re                           # Biblioteca padrão do Python para expressões regulares\n",
    "import torch                        # PyTorch (testado na versão 1.6.0)\n",
    "from torchvision import models      # Modelos de redes neurais para imagens (testado na versão 0.7.0)\n",
    "from torchvision import transforms  # Transformações de imagens\n",
    "\n",
    "def filename_to_label(file):\n",
    "    '''Função que analisa o nome de uma imagem e retorna a classe associada.\n",
    "    Operações abaixo são específicas para as imagens de dígitos.'''\n",
    "    \n",
    "    pattern = re.compile('digito_(\\d)')         # Compila expressão regular\n",
    "    m = pattern.search(file)                    # Busca um match\n",
    "    return int(m.group(1))                      # Retorna o que está dentro do parênteses na expressão regular\n",
    "\n",
    "def image_generator(root_folder, files, func_filename_to_label=None):\n",
    "    '''Gerador de imagens. `func_filename_to_label` é uma função\n",
    "    que recebe o nome de um arquivo e retorna a classe da imagem.'''\n",
    "    \n",
    "    for file in files:\n",
    "        img = Image.open(root_folder+file)\n",
    "        if func_filename_to_label is None:\n",
    "            label = None\n",
    "        else:\n",
    "            label = func_filename_to_label(file)\n",
    "        \n",
    "        yield img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura das imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = 'digitos/'\n",
    "train_folder = root_folder + 'treinamento/'\n",
    "\n",
    "files = os.listdir(train_folder)\n",
    "imgs = iter(image_generator(train_folder, files, filename_to_label))    # Cria iterador a partir de gerador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/0lEQVR4nGNgGHhgPP/vfCMccgbv/vz58xa7nNnjv3/ev/xjyYYpxWXz4M/fP6dC/vytgggwIUnOPCDDwMBgxHOQQRdD0tibkfFQKeOL85OYGLG5ZTOPd6UoA8Pfz2gOVlv69+WFEAj775+lKHLsm/58cBeWgUkeRpG0/PPHHs5Blzz2dx+C8//vEWTX+hj834SQ/Pf/ArLG0D/PJOHWt//dxYMqeR8u1/znoTsDquREKMtg6Z+1DKgg7O9DCKPo3d9FaHIMoX9+TjKQDd308O/95RaYkn/+PL3+58+fI03oUgwMMsf//Pn758/LiZhSDAwMkg1//v7pVcUqR1cAAKxwbkTVIzd2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x2B21D177D48>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experimente rodar esta célula diversas vezes usando ctrl+enter\n",
    "img, label = next(imgs)\n",
    "img_shape = img.size\n",
    "print(img_shape)\n",
    "print(label)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação da rede neural nas imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 28, 28])\n",
      "tensor([[-1.1529e+00,  5.9912e-01,  1.1856e+00,  2.0037e+00,  1.6274e+00,\n",
      "          3.3721e+00,  9.2648e-01, -1.9575e+00, -1.5715e+00, -2.7994e+00,\n",
      "         -9.4762e-01, -1.7412e+00, -1.1623e+00, -1.5199e+00, -5.1058e-01,\n",
      "         -6.8135e-01, -2.6792e-01, -1.9036e+00, -5.2568e-01, -2.3722e+00,\n",
      "         -2.0020e+00, -3.5556e-01, -4.4574e-01, -9.3151e-01, -8.4625e-01,\n",
      "         -1.0598e+00,  6.3470e-01, -1.0059e+00, -7.8321e-01, -4.6957e-01,\n",
      "         -1.3459e-01, -1.4642e+00, -6.9060e-01,  1.7900e+00,  1.3883e+00,\n",
      "         -1.6197e+00,  1.4442e-01, -1.4012e+00,  6.4662e-01, -6.0506e-01,\n",
      "         -1.1089e+00, -9.2006e-01, -1.0526e+00, -7.4314e-01, -7.0834e-01,\n",
      "         -3.3165e-01, -1.8039e+00,  7.2059e-01, -2.7064e+00, -1.7809e-02,\n",
      "          2.8596e-01, -1.7808e+00, -1.4320e+00,  7.4649e-02, -9.5867e-01,\n",
      "         -1.1376e+00, -1.1169e+00, -9.9954e-01,  5.2636e-01, -1.2430e-01,\n",
      "         -1.7088e+00, -3.3822e-01, -1.8691e+00,  1.5553e-01, -6.8265e-01,\n",
      "          2.3492e+00,  6.6181e-01,  5.9769e-01,  1.0596e-01,  1.3014e+00,\n",
      "         -1.4241e+00,  2.7263e-01, -1.4210e-01, -3.7899e-01, -6.3237e-01,\n",
      "         -6.8224e-01, -1.9680e+00, -4.7023e-01,  1.2520e+00,  3.3132e-01,\n",
      "          5.3433e-01,  3.7218e-01, -1.0627e+00, -8.0997e-01, -2.6513e+00,\n",
      "          4.7023e-01, -6.7405e-01, -9.1095e-01, -1.8088e+00, -1.5777e+00,\n",
      "         -2.9999e+00, -1.4592e+00, -1.6384e+00, -2.2417e+00, -1.6231e+00,\n",
      "         -2.3482e+00, -1.7177e+00, -2.4292e+00, -1.8437e+00, -1.4539e+00,\n",
      "         -1.4626e+00, -1.3952e+00, -8.5438e-01,  7.1831e-01, -2.5485e+00,\n",
      "         -2.8926e+00, -1.0143e+00,  1.3178e+00,  8.8974e-01, -1.0760e+00,\n",
      "         -2.1575e-01,  3.3014e+00,  1.0067e-01,  6.5825e-02, -1.2040e+00,\n",
      "          7.4336e-01, -2.3474e-01,  1.3051e+00,  4.1077e-01, -3.9079e-01,\n",
      "          5.0780e-01, -6.8553e-01, -2.7492e-01, -1.2239e+00, -7.2459e-01,\n",
      "         -2.8009e-01,  1.3843e+00, -1.8030e+00, -1.4893e+00, -1.1974e+00,\n",
      "         -2.1544e+00, -1.1182e+00, -2.7149e-01, -1.8663e+00, -1.8207e+00,\n",
      "         -1.6094e+00, -2.2852e+00, -1.3826e+00, -9.3516e-01,  6.2494e-01,\n",
      "         -1.1117e+00, -1.0011e+00, -2.4961e-01, -2.1297e-01, -2.8161e+00,\n",
      "          3.9653e-01, -5.0565e-01, -2.6384e-01, -3.1219e-02,  1.4396e+00,\n",
      "          1.0256e+00, -3.2176e-01, -1.6860e+00, -3.0112e-01, -1.5179e+00,\n",
      "         -8.1342e-01, -7.1484e-01, -1.1396e+00, -1.0111e+00, -1.3803e+00,\n",
      "         -1.9717e+00, -9.8094e-01,  7.4635e-02,  2.5696e-01, -1.7476e-01,\n",
      "         -1.3838e+00, -1.2794e+00, -1.1049e+00, -3.9467e-01, -1.6332e+00,\n",
      "         -1.2725e+00, -1.2656e+00, -1.6525e+00,  8.6986e-03, -6.5047e-01,\n",
      "         -1.3409e+00, -2.0111e+00, -1.2836e+00, -7.1810e-01, -4.3110e-01,\n",
      "         -1.8696e-01, -1.1695e+00, -9.0168e-01, -1.4138e+00, -2.1649e+00,\n",
      "         -1.8636e+00, -7.9613e-01, -1.3597e+00, -1.1428e+00, -7.1133e-01,\n",
      "         -7.7677e-01, -1.0698e+00, -1.3860e+00, -2.0132e+00, -1.1483e+00,\n",
      "          9.1782e-02, -2.5831e+00, -1.9386e+00, -1.5041e+00, -1.4501e+00,\n",
      "         -5.8889e-01, -1.3229e+00,  1.6565e-02, -4.2800e-01, -1.8123e+00,\n",
      "         -2.1344e+00, -1.6238e+00, -7.8119e-01, -4.7881e-01, -9.5997e-01,\n",
      "         -5.0062e-01,  3.9178e-02, -1.5099e+00, -8.5823e-01, -7.6976e-01,\n",
      "         -6.6169e-01, -2.0227e+00, -1.1151e+00, -1.3243e+00, -1.3648e+00,\n",
      "         -1.7988e+00, -1.1483e+00,  9.3130e-01, -9.1133e-01, -1.2966e+00,\n",
      "          6.6875e-01, -8.4461e-01, -1.1642e+00, -1.1458e+00, -1.5796e+00,\n",
      "         -1.8937e+00, -2.1612e+00, -1.1337e+00, -2.5729e-01, -8.0011e-01,\n",
      "          8.9614e-03, -9.6855e-01, -1.0321e+00, -3.7506e-01, -1.2449e+00,\n",
      "          1.2986e-03, -7.8874e-01, -1.2315e+00, -4.2777e-01, -7.0792e-01,\n",
      "         -1.3205e+00, -2.2133e-01, -1.4745e+00, -5.6951e-01, -7.1942e-01,\n",
      "         -7.8953e-01, -4.9817e-01, -1.4247e+00, -2.9970e-01, -7.6113e-02,\n",
      "         -1.5700e+00, -1.4023e+00, -1.1173e+00, -4.2661e-01, -4.2346e-01,\n",
      "         -1.3555e+00, -1.2596e+00, -2.2672e+00, -1.8305e+00, -3.6411e-01,\n",
      "         -5.0194e-01, -2.0196e+00, -2.5795e+00, -1.1084e+00, -1.1313e+00,\n",
      "          5.4396e-01, -2.8375e-02, -2.3745e-01, -1.6048e-01, -1.1040e+00,\n",
      "         -3.4992e-01, -1.2334e+00, -8.9847e-01, -6.6519e-01,  1.5992e-01,\n",
      "         -8.8410e-01, -1.2845e-01, -3.3387e-01, -9.6604e-01, -2.3763e-01,\n",
      "         -7.8162e-01, -1.4742e+00, -1.8548e+00, -1.1894e+00, -9.9672e-01,\n",
      "         -5.7800e-01, -1.9316e+00, -2.3695e+00, -1.7158e+00, -9.0876e-01,\n",
      "         -1.0530e+00,  4.2967e-01, -1.5971e+00, -1.0276e+00, -3.3987e-01,\n",
      "         -8.3699e-01, -6.8018e-01, -1.3521e+00,  6.8855e-02, -2.2477e+00,\n",
      "         -8.1988e-01, -8.4710e-01, -5.9722e-01, -5.8805e-01, -1.4806e+00,\n",
      "         -4.7193e-01, -8.5727e-01, -2.0248e+00, -9.0724e-01, -2.0708e-01,\n",
      "         -1.0508e+00, -6.2216e-01, -1.6325e-01,  1.5256e-01,  6.3261e-01,\n",
      "          5.5819e-01, -4.8574e-01,  3.7300e-01, -9.3229e-01, -1.0777e+00,\n",
      "         -1.4464e+00,  7.9055e-01, -7.6050e-01, -1.8102e+00,  6.1015e-01,\n",
      "          1.7217e-01,  7.0709e-01, -1.7429e+00, -1.5191e+00, -1.6132e+00,\n",
      "         -1.7867e+00, -7.2449e-01, -7.1316e-01, -2.9501e+00, -2.4267e+00,\n",
      "         -1.8698e+00, -1.9610e+00, -2.1024e+00, -2.6337e+00, -2.2024e+00,\n",
      "         -7.7529e-01, -2.1201e+00, -1.4318e+00, -1.2460e+00,  9.1029e-01,\n",
      "          3.4447e-02, -1.4599e+00, -2.0117e+00, -2.0494e+00, -2.2541e+00,\n",
      "         -1.6218e+00, -6.4143e-01, -7.1016e-02,  6.6059e-01, -5.5067e-01,\n",
      "         -1.3984e+00, -5.5106e-01, -3.6629e-01, -7.6239e-01, -6.7843e-01,\n",
      "          3.1953e-01, -7.7302e-01, -3.6805e-01, -4.8042e-01, -7.5882e-01,\n",
      "         -2.0896e+00, -1.7948e+00, -1.1689e+00, -2.3073e+00, -1.0402e+00,\n",
      "         -1.8820e+00, -9.2260e-02, -9.6355e-01, -1.2839e+00, -8.6955e-01,\n",
      "         -1.7329e+00, -2.6183e+00, -1.7495e+00, -2.2082e+00, -3.4187e-01,\n",
      "         -1.6890e+00, -2.1532e+00, -1.3768e+00, -1.3485e+00, -7.1254e-01,\n",
      "         -8.9338e-01,  8.5624e-01, -3.5662e-01,  5.0993e-01,  9.1099e-01,\n",
      "         -6.3118e-03, -5.7162e-01,  4.8523e-02,  1.6178e+00,  2.0823e+00,\n",
      "         -6.2958e-01,  1.2791e+00,  2.0351e+00,  3.5267e+00,  7.1305e-01,\n",
      "          2.3943e+00, -1.4853e+00,  6.9091e-01,  2.5046e-01,  3.5246e+00,\n",
      "         -2.1083e+00, -3.0151e-01,  1.2327e+00,  4.4616e-01,  1.7680e+00,\n",
      "         -7.8990e-02,  6.6311e-03,  1.2202e-02,  3.7660e+00,  1.6010e+00,\n",
      "         -2.2567e-01, -1.4963e-01,  3.5388e+00, -1.0389e+00,  4.9589e-01,\n",
      "         -2.2911e+00,  3.1213e+00,  8.6442e-01,  2.7744e-02,  1.1443e+00,\n",
      "         -2.5113e-02,  5.4697e-01,  2.3881e-01,  1.0215e+00, -3.3103e-01,\n",
      "          1.7637e+00, -6.7370e-01, -1.8060e+00,  3.3889e+00,  3.4789e-01,\n",
      "          1.0165e+00,  1.5828e-01,  2.1143e-01,  3.1900e-01,  9.0391e-02,\n",
      "          2.6652e-03,  1.6285e+00,  3.1423e-02, -1.6187e+00, -1.9983e+00,\n",
      "          1.2940e+00, -4.6047e-01, -8.7248e-01, -1.0766e+00,  1.1278e+00,\n",
      "          1.7842e+00, -9.1598e-01,  7.9745e-01,  4.7404e+00,  1.6344e+00,\n",
      "          7.7911e-01,  5.5574e-02,  5.7058e-01,  9.3315e-01,  1.2924e-01,\n",
      "          2.2516e+00,  6.1110e-01, -1.4006e+00,  1.1361e+00,  5.0571e-02,\n",
      "          1.7303e+00,  1.2264e+00,  4.9830e-01,  2.1260e+00, -1.4375e+00,\n",
      "          5.7360e-01, -3.3099e+00,  1.1126e+00,  1.6803e+00,  8.7419e-01,\n",
      "          3.1083e+00,  2.4397e+00,  1.6220e+00, -2.1418e+00, -9.0033e-01,\n",
      "          3.5030e+00, -1.6064e+00,  5.6644e+00,  2.1037e+00,  4.8259e-01,\n",
      "          8.5574e-01,  2.0854e-01,  3.9599e-03, -1.2481e+00,  1.3334e-01,\n",
      "         -1.1230e+00, -1.2718e-01, -2.0711e+00, -1.0722e+00,  1.6978e+00,\n",
      "         -1.5218e+00, -1.2212e+00,  2.7675e-01, -4.5772e-01,  1.3099e+00,\n",
      "          6.1166e-01,  2.0092e-01,  3.3187e+00,  7.1488e+00,  1.1364e-01,\n",
      "          2.9250e+00, -1.0254e+00,  3.1657e-01,  3.2110e-01, -1.8493e-01,\n",
      "          1.1065e+00,  1.4586e-01,  2.0261e-02,  5.2108e-01,  1.1871e-01,\n",
      "          5.5722e-01,  1.0971e-01, -2.5837e+00, -2.3002e-01,  5.5851e-01,\n",
      "         -8.7831e-01,  2.6598e+00,  1.8517e+00,  4.7918e+00,  9.3932e-02,\n",
      "          2.3146e+00,  2.1931e+00, -4.8902e-01, -1.3235e+00,  6.5216e-01,\n",
      "          1.1737e+00, -1.1263e-01, -7.3763e-01, -1.4467e+00,  1.1146e+00,\n",
      "          2.9983e-01,  6.1667e-01,  1.0640e+00,  4.6899e+00,  1.0451e+00,\n",
      "          2.6085e+00,  2.8585e+00, -1.3725e+00, -9.3254e-01,  3.1467e+00,\n",
      "          1.2257e+00,  1.7998e+00,  3.4159e-02,  2.1888e+00, -9.0541e-01,\n",
      "          8.2156e-01,  2.5688e-01, -1.6935e+00,  1.7049e-01,  8.9492e-01,\n",
      "          1.1516e-02, -1.5441e-01, -7.4159e-01,  1.6643e+00, -2.1640e+00,\n",
      "          2.0334e+00,  8.3887e-01,  2.4615e-01, -1.5310e+00,  2.0968e+00,\n",
      "          1.6182e-01,  1.2129e+00, -1.8720e-01,  8.5380e-01,  2.9317e+00,\n",
      "          5.4989e-01, -1.6866e+00,  8.0172e-01, -6.8950e-01, -2.6439e-02,\n",
      "         -1.9710e+00,  3.7399e-01, -5.8044e-02, -1.4187e-01,  1.7792e+00,\n",
      "          7.0561e-01,  2.2599e+00,  8.6268e-01,  4.5233e-01,  1.0322e+00,\n",
      "          3.4664e+00,  4.9725e-01,  4.9889e+00,  2.9790e+00, -7.0463e-02,\n",
      "         -9.1647e-01,  1.0162e+00, -2.0170e-01,  4.6741e-01,  3.4376e-01,\n",
      "          1.8714e+00, -9.1746e-04, -1.0187e+00, -1.5720e+00,  3.1562e-01,\n",
      "          5.9145e+00,  1.3962e+00, -1.1341e+00,  9.4172e-01,  8.6271e-01,\n",
      "          2.4205e+00,  8.2218e-01, -1.2255e+00,  2.5263e+00, -8.0658e-01,\n",
      "          1.1219e+00, -5.4024e-01,  9.2958e-01,  1.5500e+00, -1.4641e+00,\n",
      "          5.1113e+00,  6.5655e-01,  3.7617e+00,  2.1435e+00,  7.2023e-04,\n",
      "         -7.3419e-03,  2.3762e+00,  5.9831e-01,  1.5533e+00,  2.5889e+00,\n",
      "         -3.9117e-01,  1.7732e+00,  3.3465e+00,  3.2638e+00, -1.4680e+00,\n",
      "          2.9121e+00,  1.6076e+00,  1.8549e+00, -8.1310e-03, -2.3709e-01,\n",
      "          1.8181e+00,  3.3240e-01, -1.0071e+00, -6.5284e-01,  1.2751e+00,\n",
      "         -2.8392e+00,  1.2990e+00,  2.6111e+00, -1.5116e+00, -4.3214e-01,\n",
      "          1.7278e+00,  6.6187e-01,  2.5586e+00,  2.9682e-02, -5.7757e-01,\n",
      "         -2.6099e-01,  8.1025e-01,  2.8730e+00, -1.2613e+00, -3.5333e-01,\n",
      "          3.9713e-01, -7.9624e-01,  4.5132e+00, -1.7701e+00,  2.6770e+00,\n",
      "          1.3563e-01,  7.4996e-01,  8.9016e-01, -1.1517e+00, -7.7860e-01,\n",
      "          1.7742e+00,  8.8123e-02, -9.0175e-01,  3.8246e+00,  6.5469e-01,\n",
      "         -6.6884e-02,  2.5340e-02,  1.0249e+00, -2.2972e-01,  1.5267e+00,\n",
      "          1.3971e+00,  5.0146e+00,  7.9844e-01,  1.0023e+00,  5.3032e-01,\n",
      "          6.5515e+00,  2.8252e+00, -4.6899e-01,  3.4265e+00, -1.5036e+00,\n",
      "         -2.0215e+00,  1.7141e+00,  2.2695e+00,  7.8452e-01, -1.5658e+00,\n",
      "          1.8642e+00, -1.8204e-01,  9.1526e-01, -2.0271e+00,  6.0564e-01,\n",
      "          1.0632e+00,  1.1886e-01, -1.0010e+00, -1.0090e+00,  2.3964e+00,\n",
      "         -1.6920e+00, -1.5507e+00,  3.3312e+00, -1.3545e+00,  2.0177e-01,\n",
      "          1.5200e+00,  1.7749e+00,  3.0347e+00,  1.1611e+00,  5.0918e+00,\n",
      "          1.6625e+00,  2.8944e-01, -1.7033e+00, -4.3673e-01,  2.5261e+00,\n",
      "          2.6421e+00,  6.9661e-01,  2.0493e+00,  9.4981e-02, -1.6408e+00,\n",
      "         -8.0167e-01,  1.0173e+00,  3.3264e-01,  7.4890e-01, -1.9905e-01,\n",
      "         -1.2198e+00,  1.0620e+00,  2.0593e+00, -7.3103e-01,  9.1786e-01,\n",
      "         -6.0958e-01,  4.6708e-02,  1.6287e+00, -6.1180e-01, -5.0082e-01,\n",
      "          2.7244e-01, -2.2254e+00,  2.0222e+00, -5.5393e-01,  3.2662e+00,\n",
      "          4.0974e+00,  3.2499e+00, -2.0015e+00,  2.4866e+00,  1.2061e+00,\n",
      "         -3.5883e-01,  1.1513e+00,  1.8697e+00,  9.2374e-01,  3.7681e+00,\n",
      "          2.4445e+00, -1.1816e+00,  1.7179e+00, -3.4055e-01,  2.8244e+00,\n",
      "          5.0403e-01,  6.3056e+00, -1.3060e+00,  4.3683e-01,  9.4381e-01,\n",
      "         -1.1486e+00, -4.0032e-01,  3.9007e+00,  1.2732e+00,  2.3756e+00,\n",
      "          8.1440e-01,  3.9576e+00,  3.5140e+00,  8.9995e-01,  2.2278e+00,\n",
      "         -1.5525e+00,  6.9411e-01,  5.7502e-01,  7.2524e-01, -1.0182e+00,\n",
      "         -3.4715e+00,  3.2660e+00,  2.8801e+00,  3.6352e+00,  2.3437e+00,\n",
      "          1.8570e+00,  2.3445e+00,  5.5084e-01,  1.3792e+00, -1.0232e+00,\n",
      "          7.3719e-01,  1.0479e+00,  6.4272e-01,  8.1081e-01,  2.5739e+00,\n",
      "          1.2457e+00,  1.0538e-01,  4.1703e-01,  3.3096e+00, -6.0663e-01,\n",
      "         -1.5265e+00, -1.0569e+00,  1.2104e+00, -6.2737e-01,  6.8825e-01,\n",
      "          2.6819e-01, -1.0384e+00,  1.4735e+00, -3.0298e-01, -8.3072e-02,\n",
      "          6.8917e+00,  7.3823e-01,  2.5700e+00,  1.7480e+00,  2.1101e-01,\n",
      "          1.3124e+00, -1.7088e-01,  2.3134e-01,  1.8605e+00,  2.0505e+00,\n",
      "          3.9751e-01, -1.3874e+00,  1.2041e+00,  1.2017e+00, -1.8540e+00,\n",
      "          1.5323e-01,  2.2454e+00, -2.1880e+00,  2.3493e+00, -1.9737e+00,\n",
      "          1.0436e+00,  3.8622e-01, -1.2640e+00,  7.7393e-01,  4.1433e-01,\n",
      "          1.5275e+00,  1.3011e+00,  1.8905e+00,  9.1137e-01, -1.6012e+00,\n",
      "         -5.6386e-01, -8.4124e-02, -1.5589e-02, -1.1417e+00,  4.6611e+00,\n",
      "          2.5565e+00, -1.1890e+00,  3.8482e+00,  3.1235e+00,  2.0831e-01,\n",
      "         -6.3476e-02,  1.3755e+00,  1.2882e+00, -1.5836e+00, -1.2393e+00,\n",
      "          2.2500e+00, -2.3184e+00, -1.8944e+00, -9.7726e-01,  7.2770e-01,\n",
      "          1.1407e+00,  1.6645e+00,  1.6700e+00, -2.0642e-01,  5.0558e-01,\n",
      "         -1.4721e-01, -7.9607e-01,  1.9125e+00,  1.2751e+00, -7.3439e-02,\n",
      "         -3.4047e-01, -8.7117e-01,  1.7425e+00, -1.3209e+00, -1.3820e+00,\n",
      "          5.3454e-01,  5.9329e-01, -4.6021e-01,  6.8908e+00, -1.7337e-01,\n",
      "         -1.4361e+00, -3.0369e-01,  2.9143e-01, -8.6951e-01, -1.5340e+00,\n",
      "         -1.4809e+00,  1.5345e+00, -2.1359e+00, -1.2988e+00, -1.5844e+00,\n",
      "          5.7418e-02,  1.7267e+00,  2.9540e+00,  1.0184e+00, -2.6581e+00,\n",
      "          3.1063e+00,  6.7125e-01,  2.4678e-01,  1.2931e+00,  4.9446e-01,\n",
      "         -9.9698e-01,  5.5322e-01,  2.3974e+00,  3.1392e-02, -9.0172e-01,\n",
      "         -1.0360e+00,  4.5516e-01,  1.7036e+00,  5.5041e-01,  9.5052e-01,\n",
      "          3.6737e-01, -3.3623e-01, -7.4765e-01,  1.2741e+00, -1.0900e+00,\n",
      "         -2.4301e+00,  3.0686e+00,  1.9839e+00,  3.9564e+00,  2.2630e+00,\n",
      "          1.9289e+00,  3.7409e+00,  3.7527e+00, -2.5656e-01, -9.2455e-01,\n",
      "          1.7000e-01, -7.3577e-01, -1.7528e+00, -1.0635e+00,  2.0826e+00,\n",
      "         -1.3374e+00, -1.4167e+00, -3.4780e-01, -1.8671e+00, -1.1628e+00,\n",
      "         -1.6727e+00, -1.4588e+00, -7.1212e-01, -1.6137e+00, -1.2290e+00,\n",
      "         -1.1175e+00, -8.0691e-01, -1.2332e+00, -2.2552e-01, -1.4049e+00,\n",
      "         -1.1815e+00, -1.4804e+00, -1.6963e+00,  1.6525e+00, -8.9002e-01,\n",
      "          4.1469e-01,  4.8122e-01,  4.8455e-01, -1.0774e+00, -1.1035e+00,\n",
      "         -1.8033e+00, -9.8338e-01,  5.4522e-01, -9.8608e-01, -8.8909e-01,\n",
      "         -1.0067e+00, -5.2789e-01, -1.2241e+00, -2.3821e+00, -1.1340e+00,\n",
      "         -5.3562e-01,  6.0446e-01,  8.6014e-01,  1.0871e+00, -9.6162e-01,\n",
      "         -2.2829e-01,  3.1497e+00, -7.8144e-01,  6.6421e-01, -5.1706e-01,\n",
      "         -7.8514e-01, -7.1288e-01,  4.1381e-01, -2.1681e-01, -9.2768e-01,\n",
      "          6.0450e-01,  9.8224e-01, -1.7720e+00,  1.5018e+00, -7.1685e-01,\n",
      "         -1.2879e-01, -2.2188e+00,  8.3252e-01, -1.2697e+00, -5.4902e-01,\n",
      "         -2.2502e+00, -1.6995e+00, -2.1314e+00, -6.4643e-01, -1.5745e+00,\n",
      "         -6.3449e-01, -5.1521e-01, -1.9077e+00,  8.9061e-02,  2.2486e+00]],\n",
      "       grad_fn=<AddmmBackward>) torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "# Carrega o modelo de rede neural resnet18. Existem inúmeros outros modelos de rede. Esta rede foi pré-treinada\n",
    "# na base de imagens ImageNet, que possui milhões de imagens, para classificar as imagens em 1000 classes distintas. \n",
    "# O comando model.eval() indica que a rede será usada apenas para extração de descritores (não haverá treinamento).\n",
    "model = models.resnet18(pretrained=True)         \n",
    "model.eval()\n",
    "\n",
    "# Para aplicarmos a rede neural na imagem precisamos realizar diversos passos de conversão:\n",
    "# 1. Obtemos o próximo elemento da base de dados\n",
    "img, label = next(imgs)\n",
    "\n",
    "# 2. A rede neural espera uma imagem colorida. Como as nossas imagens são em níveis de cinza,\n",
    "# convertemos a imagem para RGB. A imagem resultante possui 3 canais idênticos\n",
    "img = img.convert('RGB')\n",
    "\n",
    "# 3. É esperado um objeto to tipo torch.Tensor, que se comporta basicamente como um array numpy,\n",
    "# mas precisamos converter explicitamente para esse tipo. O submódulo `transforms` do PyTorch \n",
    "# possui a classe `ToTensor` para conversão de imagens Pillow para tensor. Como ela é uma classe,\n",
    "# criamos uma instância dela e imediatamente aplicamos na imagem\n",
    "img = transforms.ToTensor()(img)\n",
    "\n",
    "# 4. O PyTorch sempre trabalha com batches de imagem. Isto é, ao invés de enviarmos sempre uma única\n",
    "# imagem para a rede enviamos um conjunto de n imagens simultaneamente. É muito mais eficiente\n",
    "# processar diversas imagens de uma vez do que cada imagem separadamente. Portanto, a rede neural\n",
    "# espera sempre um batch de imagens. Um batch possui sempre 4 dimensões, organizadas da seguinte forma\n",
    "# [tamanho do batch, número de canais, número de linhas, número de colunas]\n",
    "# Como temos apenas uma imagem, precisamos criar um batch (um array de 4 dimensões) contendo apenas\n",
    "# uma imagem. Isso é feito pelo método `unsqueeze(0)`, que adiciona uma dimensão no começo do array\n",
    "img = img.unsqueeze(0)\n",
    "print(img.shape)\n",
    "\n",
    "# 5. Finalmente, aplicamos o modelo na imagem\n",
    "descriptors = model(img)\n",
    "print(descriptors, descriptors.shape)\n",
    "\n",
    "# Os comandos acima podem ser chamados em uma única linha\n",
    "#img = transforms.ToTensor()(img.convert('RGB')).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Definição do dispositivo usado para processamento da rede. 'cuda' indica que será usada a GPU.\n",
    "# Caso uma GPU com núcleos cuda (GPU NVIDIA) não esteja disponível, é necessário mudar o valor para 'cpu'.\n",
    "# Nesse caso, o processamento será mais demorado.\n",
    "DEVICE = 'cuda'                \n",
    "\n",
    "def get_descriptors(imgs, model, bs, num_files, descriptor_size):\n",
    "    '''Obtém descritores para as imagens do iterável `imgs`. O resultado da aplicação de `model`\n",
    "    é usado como descritor. Note que seria mais apropriado realizar um treinamento adicional da rede\n",
    "    para obtenção de descritores mais apropriados para o nosso problema. Mas esse é um assunto\n",
    "    para o futuro...\n",
    "    \n",
    "    Parâmetros\n",
    "    ----------\n",
    "    imgs : iterável\n",
    "        Iterável que retorna uma imagem e um rótulo a cada chamada \n",
    "    model : torch.nn.Module\n",
    "        Rede neural do PyTorch\n",
    "    bs : int\n",
    "        Tamanho do batch\n",
    "    num_files : int\n",
    "        Número de elementos em `imgs`\n",
    "    descriptor_size : int\n",
    "        Número de descritores retornado por `model`\n",
    "    '''\n",
    "        \n",
    "    model.eval()\n",
    "    model.to(DEVICE)                                     # Coloca o modelo em DEVICE (usualmente a GPU)\n",
    "    data = np.zeros((num_files, descriptor_size))\n",
    "    labels = np.zeros(num_files, dtype=int)\n",
    "    \n",
    "    img, label = next(imgs)                                 # Verifica primeiro elemento para obter o tamanho da imagem\n",
    "    img_shape = img.size                           \n",
    "    batch = torch.zeros((bs, 3, img_shape[1], img_shape[0]))         \n",
    "    batch[0] = transforms.ToTensor()(img.convert('RGB'))\n",
    "    labels[0] = label\n",
    "    \n",
    "    # Vamos iterar sobre as imagens construindo batches contendo `bs` imagens. Quando um batch estiver\n",
    "    # completo, aplicamos o modelo no batch\n",
    "    for idx, (img, label) in enumerate(imgs, start=1):\n",
    "\n",
    "        batch_idx = idx//bs\n",
    "        idx_in_batch = idx - batch_idx*bs\n",
    "        batch[idx_in_batch] = transforms.ToTensor()(img.convert('RGB'))\n",
    "        labels[idx] = label\n",
    "\n",
    "        if (idx+1)%bs==0:                         # Se completou um batch\n",
    "            batch = batch.to(DEVICE)              # Move o batch para a GPU (se disponível)\n",
    "\n",
    "            with torch.no_grad():                 # Esse comando indica que não iremos otimizar a rede\n",
    "                output = model(batch)\n",
    "\n",
    "            data[batch_idx*bs:(batch_idx+1)*bs] = np.array(output.to('cpu'))   # Salva os valores em um array \n",
    "\n",
    "            batch = torch.zeros_like(batch)                                    # Reseta o batch\n",
    "            \n",
    "    return data, labels\n",
    "\n",
    "# Criamos o iterador novamente para incluir as imagens que já foram iteradas nas células acima\n",
    "imgs = iter(image_generator(train_folder, files, filename_to_label))\n",
    "data, labels = get_descriptors(imgs, model, 20, len(files), 1000)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do classificador SVM usando os descritores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cria uma instância do classificador SVM. `C` é um parâmetro do classificador\n",
    "# Essa célula pode demorar um pouco para rodar\n",
    "svm = sklearn.svm.SVC(C=100)      \n",
    "svm.fit(data, labels)              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconhecimento de caracteres contidos em novas imagens\n",
    "\n",
    "Vamos agora aplicar o nosso classificador em novas imagens para as quais não sabemos a classe. Para isso, para cada nova imagem precisamos obter os descritores e aplicar o classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(img, model, svm):\n",
    "    '''Retorna a classe da imagem `img` usando os descritores de `model` e \n",
    "    o classificador `svm`'''\n",
    "    \n",
    "    img = transforms.ToTensor()(img.convert('RGB')).unsqueeze(0)\n",
    "    img = img.to(DEVICE)\n",
    "    with torch.no_grad(): \n",
    "        output = model(img)\n",
    "    descriptor = np.array(output.to('cpu'))\n",
    "    return svm.predict(descriptor)\n",
    "\n",
    "# Carrega um novo conjunto de imagens\n",
    "test_folder = root_folder+'teste/'\n",
    "files = os.listdir(test_folder)\n",
    "imgs = iter(image_generator(test_folder, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA4UlEQVR4nGNgGGSAEc7iqGE1Xzf/M1ZV7kf//fv370E+CxY5rw///j04efXfvy2Ysprv/v1rkGUQuPzvHyuGpNm/+zZMDAwMKlv+9WNIspdpQhgWX3/o4nQ984t/2XAOE5pkhhgSB9VtVmkBDP/f4TB02r///+bjslHr7b9/13G6R2HDv78TFHHJcvr8+XcEp16G7f/+ueKU5Pn/rxunpOW/fy+UscqIOJX//ffvPD+GBFPIvFO3/v379++9B7qU3527//79+/fv0sxQWZgYPJmw2bpYnDh1++nPbzhdQy0AAE3VWHPygYtaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x2B21D177A48>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experimente rodar esta célula diversas vezes usando ctrl+enter\n",
    "img, _ = next(imgs)\n",
    "label = get_label(img, model, svm)\n",
    "print(label)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificação que uma camada convolucional é de fato uma operação de convolução\n",
    "\n",
    "Vamos verificar se uma camada de convolução de uma rede neural realmente é uma operação de convolução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição das variáveis\n",
    "\n",
    "# Imagem\n",
    "img = torch.tensor([[1, 3, 1, 2],\n",
    "                    [0, 2, 1, 4],\n",
    "                    [2, 1, 0, 1],\n",
    "                    [3, 1, 2, 3]]).float()\n",
    "\n",
    "# Filtro\n",
    "w = torch.tensor([[1, 1, 1],\n",
    "                  [1, 1, 1],\n",
    "                  [1, 1, 1]]).float()\n",
    "\n",
    "padding = 1\n",
    "kernel_size = w.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 6.,  8., 13.,  8.],\n",
      "          [ 9., 11., 15.,  9.],\n",
      "          [ 9., 12., 15., 11.],\n",
      "          [ 7.,  9.,  8.,  6.]]]], grad_fn=<MkldnnConvolutionBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn      # nn é um submódulo possuindo diversos tipos de camadas de redes neurais\n",
    "\n",
    "# Definição da camada de convolução. A camada possui 1 canal de entrada, 1 canal de saída (porque temos apenas 1 kernel) e \n",
    "# preenchimento com 0 para evitar problemas na borda. Por padrão, é somado um valor ao resultado da convolução, chamado \n",
    "# de bias, bias=False indica que não queremos somar esse valor.\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=kernel_size, padding=padding, \n",
    "                   bias=False, padding_mode='zeros')\n",
    "\n",
    "# Por padrão, os valores do filtro da camada possuem valores aleatórios. Esse filtro é o atributo conv2d.weight.\n",
    "# Esse atributo possui dimensão [1, 1, 3, 3], que é equivalente a um batch de tamanho 1, pois temos apenas\n",
    "# 1 imagem na entrada, 1 filtro na camada e esse filtro possui tamanho 3x3\n",
    "# Podemos mudar os valores de duas formas:\n",
    "\n",
    "# Mudando os valores in-place\n",
    "conv2d.weight[:] = w.view(1, 1, 3, 3)\n",
    "\n",
    "# Criando um novo parâmetro e associando ao atributo\n",
    "conv2d.weight = nn.Parameter(w.view(1, 1, 3, 3))\n",
    "\n",
    "# A imagem precisa ter dimensão 4 ([tamanho do batch, num canais, num linhas, num colunas])\n",
    "res_conv2d = conv2d(img.view(1, 1, 4, 4))\n",
    "print(res_conv2d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
